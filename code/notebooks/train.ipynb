{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils import (\n",
    "    load_data,\n",
    "    process_labels,\n",
    "    CustomTokenizer,\n",
    "    CustomTrainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up path\n",
    "excel_fpath = r\"D:\\Priyanshu\\Wysa\\dataset.xlsx\"\n",
    "mappings_fpath = r\"D:\\Priyanshu\\Wysa\\code\\mappings\\mapping.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>iPad App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>iPad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>Android App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>iPad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>iPad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     category\n",
       "0   5     iPad App\n",
       "1  15         iPad\n",
       "2  31  Android App\n",
       "3  32         iPad\n",
       "4  33         iPad"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug = pd.read_csv(\"aug_data.csv\")\n",
    "df_aug.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_category_list = [\n",
    "    \"iPhone\",\n",
    "    \"iPad or iPhone App\",\n",
    "    \"iPad\",\n",
    "    \"Google\",\n",
    "    \"Android\",\n",
    "    \"Apple\",\n",
    "    \"Android App\",\n",
    "    \"Other Google product or service\",\n",
    "    \"Other Apple product or service\",\n",
    "]\n",
    "\n",
    "mapping = {\n",
    "    \"IPad\": \"iPad\",\n",
    "    \"Other Apple Product or Service\": \"Other Apple product or service\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_category(category):\n",
    "    if pd.isna(category):\n",
    "        return False\n",
    "    return category.lower() in [item.lower() for item in valid_category_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of augmented samples: 4550\n",
      "No. of classes: 9\n"
     ]
    }
   ],
   "source": [
    "df_aug_cleaned = df_aug[df_aug[\"category\"].apply(is_valid_category)]\n",
    "df_aug_cleaned.loc[:, \"category\"] = df_aug_cleaned[\"category\"].replace(mapping)\n",
    "\n",
    "print(f\"No. of augmented samples: {len(df_aug_cleaned)}\")\n",
    "print(f\"No. of classes: {len(df_aug_cleaned['category'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Augmented Data with Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>brand_product_name</th>\n",
       "      <th>emotion_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  brand_product_name  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "   emotion_category  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get original data\n",
    "df_orig = load_data(excel_fpath, \"Train\")\n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_4408\\2957993209.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_orig[\"brand_product_name\"].update(df_aug_cleaned[\"category\"])\n"
     ]
    }
   ],
   "source": [
    "# Merge brand product categories\n",
    "if all(idx in df_orig.index.tolist() for idx in df_aug_cleaned[\"id\"].tolist()):\n",
    "    df_orig[\"brand_product_name\"].update(df_aug_cleaned[\"category\"])\n",
    "    df_merged = df_orig.dropna(subset=[\"brand_product_name\"])\n",
    "    # df_merged.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    print(\"Semething wrong...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet                 0\n",
       "brand_product_name    0\n",
       "emotion_category      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mappings_fpath, \"r\") as file:\n",
    "    mappings = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>brand_product_name</th>\n",
       "      <th>emotion_category</th>\n",
       "      <th>brand_product_name_label</th>\n",
       "      <th>emotion_category_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>Props to GSDM and the big G. (google) at #SXSW...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4655</th>\n",
       "      <td>At the google dev event surrounded by people m...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>RT @mention #fsw #sxsw for those of you who wa...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>Foursquare ups the game, just in time for #SXS...</td>\n",
       "      <td>Other Apple product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>#SXSW movers &amp;amp; shakers, @mention is publis...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  \\\n",
       "3172  Props to GSDM and the big G. (google) at #SXSW...   \n",
       "4655  At the google dev event surrounded by people m...   \n",
       "4927  RT @mention #fsw #sxsw for those of you who wa...   \n",
       "2594  Foursquare ups the game, just in time for #SXS...   \n",
       "2847  #SXSW movers &amp; shakers, @mention is publis...   \n",
       "\n",
       "                   brand_product_name                    emotion_category  \\\n",
       "3172                           Google                    Positive emotion   \n",
       "4655  Other Google product or service  No emotion toward brand or product   \n",
       "4927                             iPad  No emotion toward brand or product   \n",
       "2594   Other Apple product or service                    Positive emotion   \n",
       "2847  Other Google product or service  No emotion toward brand or product   \n",
       "\n",
       "      brand_product_name_label  emotion_category_label  \n",
       "3172                         7                       1  \n",
       "4655                         3                       2  \n",
       "4927                         1                       2  \n",
       "2594                         5                       1  \n",
       "2847                         3                       2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled = process_labels(\n",
    "    df_merged,\n",
    "    [\"brand_product_name\", \"emotion_category\"],\n",
    "    [mappings[\"categories\"], mappings[\"emotions\"]],\n",
    ")\n",
    "df_labeled.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Emotion Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EMOTIONS = len(df_labeled[\"emotion_category_label\"].unique())\n",
    "NUM_EMOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet', 'emotion_category_label'],\n",
       "    num_rows: 6001\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df_labeled[[\"tweet\", \"emotion_category_label\"]])\n",
    "dataset = dataset.remove_columns([\"__index_level_0__\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99066a4d927541a7b95add3731e7580f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tweet', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 6001\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tokenizer\n",
    "tokenizer = CustomTokenizer(model_id=\"bert-base-cased\")\n",
    "\n",
    "# Tokenize the data (tweets)\n",
    "dataset = tokenizer(docs=dataset, column=\"tweet\")\n",
    "dataset = dataset.rename_column(\"emotion_category_label\", \"labels\")\n",
    "dataset = DatasetDict({\"train\": dataset})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\Priyanshu\\Wysa\\venv\\Lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "d:\\Priyanshu\\Wysa\\code\\utils\\trainer.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  self.trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Get trainer\n",
    "trainer = CustomTrainer(\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    model_id=\"bert-base-cased\",\n",
    "    num_classes=NUM_EMOTIONS,\n",
    "    output_dir=r\"D:\\Priyanshu\\Wysa\\checkpoints\\emotion_recog\",\n",
    "    num_train_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Brand/Product Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CATEGORIES = len(df_labeled[\"brand_product_name_label\"].unique())\n",
    "NUM_CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet', 'brand_product_name_label'],\n",
       "    num_rows: 6001\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df_labeled[[\"tweet\", \"brand_product_name_label\"]])\n",
    "dataset = dataset.remove_columns([\"__index_level_0__\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f11f4454e8419ebb2a8381cddd1021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tweet', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 6001\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tokenizer\n",
    "tokenizer = CustomTokenizer(model_id=\"bert-base-cased\")\n",
    "\n",
    "# Tokenize the data (tweets)\n",
    "dataset = tokenizer(docs=dataset, column=\"tweet\")\n",
    "dataset = dataset.rename_column(\"brand_product_name_label\", \"labels\")\n",
    "dataset = DatasetDict({\"train\": dataset})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\Priyanshu\\Wysa\\venv\\Lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "d:\\Priyanshu\\Wysa\\code\\utils\\trainer.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  self.trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Get trainer\n",
    "trainer = CustomTrainer(\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    model_id=\"bert-base-cased\",\n",
    "    num_classes=NUM_CATEGORIES,\n",
    "    output_dir=r\"D:\\Priyanshu\\Wysa\\checkpts\\brand_product_recog\",\n",
    "    num_train_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
